$ ./run_inference.sh
.Building prediction
Downloading: "https://download.pytorch.org/models/densenet121-a639ec97.pth" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth
100.0% * Serving Flask app "app" (lazy loading)
 * Environment: production
   WARNING: This is a development server. Do not use it in a production deployment.
   Use a production WSGI server instead.
 * Debug mode: on

 * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)
 * Restarting with stat
 * Debugger is active!
 * Debugger PIN: 742-774-761
172.17.0.1 - - [10/May/2021 13:30:26] "HEAD / HTTP/1.1" 200 -
172.17.0.1 - - [10/May/2021 13:30:27] "POST /run_inference HTTP/1.1" 200 -
{'class_id': 'n03032252', 'class_name': 'cinema'}